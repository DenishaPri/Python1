# -*- coding: utf-8 -*-
"""LVADUSUR81-DENISHAPRIYAG-FINAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xxqPjXzWlgSebuYAkR4-c670LXF9QBK0
"""

#1

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
df = pd.read_csv('/content/Walmart_Dataset Python_Final_Assessment.csv')
# print(df)
print('Info')
df.info()
num_rows, num_columns = df.shape
print("number of rows:", num_rows)
print("number of columns",num_columns)
print()
print("Data types of columns:")
print(df.dtypes)
print()
print("summary:")
print(df.describe())
print()
print()
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
categorical_columns = df.select_dtypes(include=['object']).columns
print('numerical_columns: ',numerical_columns)
print('categorical_columns: ',categorical_columns)
print('list of column')
df.columns.tolist() #list of column
# print(df)

#2
missing_values = df.isnull().sum()
print("Missing values:")
print(missing_values)
print()
data = df.dropna()
duplicate_entries = data.duplicated().sum()
print("Number of duplicate entries:", duplicate_entries)
print()
data = data.drop_duplicates()

#3
numerical_data = df.select_dtypes(include=['int64', 'float64'])
summary_stats = numerical_data.describe()
mode_values = numerical_data.mode().iloc[0]
data_range = numerical_data.max() - numerical_data.min()
summary_stats.loc['mode'] = mode_values
summary_stats.loc['range'] = data_range
variance = numerical_data.var()
std_deviation = numerical_data.std()
summary_stats.loc['variance'] = variance
summary_stats.loc['std_deviation'] = std_deviation
print("Summary statistics for numerical data:")
print(summary_stats)

# numerical_data = ['Sales','Quantity','Profit']
# mode_values = numerical_data.mode()
# mean_values = numerical_data.mean()
# data_range = numerical_data.max() - numerical_data.min()
# variance = numerical_data.var()
# std_deviation = numerical_data.std()

#4
print('Plotting histogram of numerical column')
plt.figure(figsize=(4, 4))
sns.histplot(numerical_data, bins=20, kde=True)
plt.title('Histogram of Numerical Column')
plt.xlabel('Value')
plt.ylabel('Frequency')
plt.show()

print('Plotting for Distribution of sales')
plt.figure(figsize=(4, 4))
sns.histplot(df['Sales'], bins=20, kde=True, color='skyblue')
plt.title('Distribution of Sales')
plt.xlabel('Sales')
plt.ylabel('Frequency')
plt.show()

print('Sales vs profit')
plt.figure(figsize=(4, 4))
sns.scatterplot(data=df, x='Sales', y='Profit', color='green')
plt.title('Sales vs. Profit')
plt.xlabel('Sales')
plt.ylabel('Profit')
plt.show()

print('Sales distribution for each category')
plt.figure(figsize=(4, 4))
sales_by_category = df.groupby('Category')['Sales'].sum()
plt.figure(figsize=(4, 4))
plt.pie(sales_by_category, labels=sales_by_category.index, autopct='%1.1f%%', startangle=140)
plt.title('Sales Distribution by Category')
plt.show()

print('Quantity vs category')
plt.figure(figsize=(4, 4))
sns.barplot(data=df, x='Category', y='Quantity', ci=None)
plt.title('Quantity by Category')
plt.xlabel('Category')
plt.ylabel('Quantity')
plt.xticks(rotation=90)
plt.show()

#5
correlation_matrix = df.corr()
print('The correlation of sales - quantity - profit')
print()
print('Correlation headmap')
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", annot_kws={"size": 10})
plt.title('Correlation Heatmap')
plt.show()
print()
print('Correlation')
print(df.corr())

"""#Outliers"""

#6
#creating a box plot (numerical columns)
for i in numerical_columns:
  plt.figure(figsize = (5,5))
  sns.boxplot(data=df[i])
  plt.title(i)
  plt.ylabel('Values')
  plt.xticks(rotation = 45)
  plt.show()

def detect_and_treat_outliers(df,columns):

  for col in columns:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    #define bounds for outliers
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    #replace outliers with the median of column
    median = df[col].median()
    df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), median, df[col])

  return df

columns = ['Sales','Quantity','Profit']
df = detect_and_treat_outliers(df,columns)
# print(df)

#creating a box plot (outliers) (numerical columns)
for i in numerical_columns:
  plt.figure(figsize = (5,5))
  sns.boxplot(data=df[i])
  plt.title(i)
  plt.ylabel('Values')
  plt.xticks(rotation = 45)
  plt.show()

"""# 7




"""

# Trends analysis:
# 1.analyze the scales and profit trends over the year. Are there any noticeable patterns or seasonal variations?
df['Order Date'] = pd.to_datetime(df['Order Date'])

df['Year'] = df['Order Date'].dt.year

yearly_data = df.groupby('Year').agg({
    'Sales': 'sum',
    'Profit': 'sum'}).reset_index()

plt.figure(figsize=(6, 6))
plt.plot(yearly_data['Year'], yearly_data['Sales'], marker='o', label='Total Sales', color='blue')
plt.plot(yearly_data['Year'], yearly_data['Profit'], marker='o', label='Total Profit', color='green')
plt.title('Sales and Profit Trends Over the Years')
plt.xlabel('Year')
plt.ylabel('Amount')
plt.xticks(yearly_data['Year'])
plt.legend()
plt.show()


category_sales = df.groupby(['Year', 'Category'])['Sales'].sum().unstack()

plt.figure(figsize=(12, 8))
category_sales.plot(kind='line', marker='o')
plt.title('Sales Trend for Each Product Category Over the Years')
plt.xlabel('Year')
plt.ylabel('Sales')
plt.xticks(yearly_data['Year'])
plt.legend(title='Category')
plt.show()

""" Trends analysis:
 By analyze of sales and profit for each year , found that sales data has a huge rise during the year 2013 and 2014 though profit has no much change in the graph, profit has a little growth of linear.
"""

# 2.Determine the product category that has shown the most growth in terms of sales over the years
total_sales_by_category = df.groupby('Category')['Sales'].sum()
growth_category = total_sales_by_category.pct_change().idxmax()
print("The product category that has shown the most growth in terms of sales over the years is:\n", growth_category)

"""7. Customer Analysis:(i)"""

customer_group = df.groupby('EmailID')


orders_per_customer = customer_group.size()
total_sales_per_customer = customer_group['Sales'].sum()

customer_stats = pd.DataFrame({
    'Number of Orders': orders_per_customer,
    'Total Sales': total_sales_per_customer
})

sorted_customers = customer_stats.sort_values(by=['Number of Orders', 'Total Sales'], ascending=False)

top_5_customers = sorted_customers.head(5)

print("Top 5 Customers:")
print(top_5_customers)

"""By analyzing the output- buying behavior of these top customers,we get datas such as their frequency of orders, total sales contribution, and average time between orders. By the output WilliamBrown@gmail.com  found to be loyal customers bought 24 number of orders with 5523.06 total sales.

7.Customer Analysis:(ii)
"""

df['Order Date'] = pd.to_datetime(df['Order Date'])

df.sort_values(by=['EmailID', 'Order Date'], inplace=True)
df['Time Between Orders'] = df.groupby('EmailID')['Order Date'].diff()

avg_time_between_orders = df.groupby('EmailID')['Time Between Orders'].mean()

print("Average Time Between Orders for Each Customer:")
print(avg_time_between_orders)

"""7. Comprehensive analytics

i. Sales Velocity Insights:

The product with high demand [Furnishing] can be made to produce more as it has more growth compared to the other products. The quantity also can be increased for this category product.
Forecast : Comparing to the previous year 2013 - 2014 had a great increase in sales but the profit is not much in increase. Sale the product with high demand so that profit and sale increase can corelate
Order Fulfillment Insights:
 avoid delay in sales date and order date and quantity of product to the corresponding peak should be maintained.

ii. Geographic Distribution of Sales:

Underlying Factors:

Demographics: By Analyze of data in different regions  we can predict the region to be more demand than the others. Each region have dfferent category of product in demand . So increase the stock of those product help in more sales.
campaigns: Make a survey of the local people in the particular region to get the high demand category product in those area.

Targeted Marketing Strategies:

Advertising: Utilize  digital advertising to reach customers in specific geographic areas with catchy message.
Partnerships: Form partnerships with local businesses or influencers to increase brand visibility and credibility in target regions.
discounds and offer: Offer promotions and discounts tailored to the preferences and buying behavior of customers in each geographic area.

iii. Prediction of High-Value Customers:

Identifying Patterns:

 analysis to segment customers based on their purchase behavior and identify high-value segments. From the data we found that the high value customer who purchase frequently.
Predictive the pattern in behaviour of the customer so that canmake a change in future to better customer- marketer relationship.
customers with the highest potential lifetime value and build a good relationship with them. Provide them with message or greetings frequently.

Find the history of customer and get frequent  insights about customer and the behaviour . Find the drawback and change according to the demand.
"""